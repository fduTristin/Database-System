# Query Processing

## Overview

### Basic Steps in Query Processing

  ![1](pictures/9.1.png)

* parsing and translation
  * translate the query into the internal form which is then translated into **relational algebra**
* optimization
  * Generate the optimal execution plan (æ‰§è¡Œè®¡åˆ’)
* execution

### Query Optimization

```sql
select salary
from instructor 
where salary <75000
```

give its relationnal algebra

$\sigma_{salary<75000}(\Pi_{salary}(instructor))$
$\Pi_{salary}(\sigma_{salary<75000}(instructor))$

* A relational algebra expression may have many equivalent expressions
* Annotated expression specifying detailed execution strategy is called an execution-plan
  * can use an index on instructor to find instructors with salary < 75000, or
  * perform complete relation scan and discard instructors with salary â‰¥ 75000

* query optimization
  * Amongst all equivalent evaluation plans, choose the one with lowest cost
  * Cost is estimated using statistical information from the database catalog

## Measures of Query Cost

* Cost is generally measured as total elapsed time for answering query
  * disk accesses, CPU, and even network communication
* Typically disk access is the predominant cost, and is also relatively easy to be estimated
* Disk access is measured by taking into account
  * Number of seeks
  * Number of blocks read
  * Number of blocks written
    * The cost to write a block is greater than the cost to read a block
    * Data is read back after being written to ensure that the write was successful

* For simplicity, use **the number of block transfers from disk** and **the number of seeks** as the cost measure
* Cost for ğ’ƒ block transfers plus ğ‘º seeks
$ğ’ƒ âˆ— ğ’•_ğ‘» + ğ‘º âˆ— ğ’•_ğ‘º$
  * $ğ’•_ğ‘»$ : time to transfer one block, â‰ˆ0.1ms
  * $ğ’•_ğ‘º$ : time for one seek, â‰ˆ4ms
* Cost also depends on the size of the buffer in main memory
  * Large buffer reduces the need for disk access
  * Often use worst case estimates, assuming only the minimum amount of buffer storage is available

## Seletion Operation

* **file scan**
  * Search algorithms that locate and retrieve records that satisfy a selection condition
* **Index scan**
  * search algorithms that use an index
  * selection condition must be on search-key of an index

* Algorithm A1 (linear search)
  * cost estimate = $b_r$ blocks transfers + 1 seek(å‰æï¼šæ–‡ä»¶å—é¡ºåºå­˜æ”¾)
    * $b_r$: number of blocks containing records from relation r
  * if selection is on a key attribute(unique), can stop on finding record
    * average cost = $(b_r/2)$ block transfers + 1 seek
  * linear search can be applied regardless of
    * selection condition or
    * ordering of records in the file, or
    * availability of indices

* A1' (binary search)
  * Applicable if selection is an equality comparison on the attribute on which file is ordered
  * Assume that the blocks of a relation are stored contiguously
  * Cost estimate (number of disk blocks to be scanned):
    * cost of locating the first tuple by a binary search on the blocks
    * worst cost $\lceil log_2(b_r)\rceil * (t_T + t_S)$
    * If there are multiple records satisfying selection
      * Add transfer cost of the number of blocks containing records that satisfy selection condition

### Selection Using Indices

* A2 (primary index on candidate key, equality)
  * Retrieve a single record that satisfies the corresponding equality condition
  * Cost = $(h_i+1)*(t_T+t_S)$  **(B+-tree)**

* A3 (primary index on non-key, equality) Retrieve multiple records
  * Records will be on consecutive blocks
    * Let ğ‘ = number of blocks containing matching records
  * Cost = $h_i*(t_T+t_S)+t_S+t_T*b$

* A4 (equality on search-key of secondary index)
  * retrieve a single record if the search-key is a candidate key
    * cost = $(h_i+1)*(t_T+t_S)$
  * retrieve multiple records if search-key is not a candidate key
    * assume that n records satisfy
    * cost = $(h_i+n)*(t_T+t_S)$
      * can be expensive
    * each record may be on a different block
      * one block access for each retrieved record

### Selection Involving Comparisons

* Implement selections of the form $\sigma_{A\geq V}(r)$ or $\sigma_{A\leq V}(r)$ by
  * using a linear file scan or binary search, or
  * using indices in the following ways:

* A5 (primary index, comparison)
  * relation is sorted on A
  * for $\sigma_{A\geq V}(r)$ use index to find first tuple $\geq$ V and scan relation sequentially from there
  * for $\sigma_{A\leq V}(r)$ just scan relation sequentially till first tuple > V, do not use index

* A6 (secondary index, comparison)
  * for $\sigma_{A\geq V}(r)$ use index to find first index entry $geq$ V and scan **index** sequentially to find pointers to records wanted
  * for $\sigma_{A\leq V}(r)$ just scan **leaf pages of index** till first entry > V
  * In either case, retrieve records that are pointed to
    * requires an **I/O** for each record
    * Linear file scan may be cheaper if many records are to be fetched!
  
---

### Selection Operation Cost Estimation

![4](pictures/8.4.png)

---

### Implementation of Complex Selections

* conjunction(åˆå–): $\sigma_{\theta_1\wedge\theta_2\wedge\cdots\wedge\theta_n}(r)$
* A7 (conjunctive selection using one index)
  * Select a condition of ğœ½ğ’Š and algorithms A1 through A6 that results in the least cost for $\sigma_{\theta_i}(r)$
  * Test other conditions on the tuples after fetching them into memory buffer
* A8 (conjunctive selection using multiple-key index)
  * Use appropriate composite (multiple-key) index if available
* A9 (conjunctive selection by intersection of identifiers)
  * Requires indices with record pointers
  * Use corresponding index for each condition, and take intersection of all the obtained sets of record pointers
  * Then fetch records from file

* disjunction (æå–): $\sigma_{\theta_1\vee\theta_2\vee\cdots\vee\theta_n}(r)$
* A10 (disjunctive selection by union of identifiers).
  * Applicable if all conditions have available indices
* Otherwise use linear scan
  * Use the corresponding index for each condition, and take union of all the obtained sets of record pointers.
  * Then fetch records from file
* negation (å–å): $\sigma_{\urcorner\theta}(r)$
  * Use linear scan on file
  * If very few records satisfy $\urcorner\theta$, and an index is applicable to $\theta$
    * Find satisfying records using index and fetch from file

## Sorting

* We can build an index on the relation, and then use the index to read the relation in sorted order.
* May lead to one disk block access for each tuple (for non-primary indices)
* Relations that fit in memory
  * Techniques like quick-sort (å¿«é€Ÿæ’åº) can be used
* Relations that donâ€™t fit in memory
  * External sort-merge (å¤–éƒ¨æ’åºå½’å¹¶) is a good choice

* æ’å…¥æ’åºã€é€‰æ‹©æ’åºã€å†’æ³¡æ’åºã€å¿«é€Ÿæ’åºã€å †æ’åºã€å½’å¹¶æ’
  åºã€å¸Œå°”æ’åºã€äºŒå‰æ ‘æ’åºã€è®¡æ•°æ’åºã€æ¡¶æ’åºã€åŸºæ•°æ’åºâ€¦

* ä¸ç¨³å®š
  * é€‰æ‹©æ’åºï¼ˆselection sortï¼‰: $O(n^2)$
  * å¿«é€Ÿæ’åºï¼ˆquicksortï¼‰: $O(nlogn)$ å¹³å‡æ—¶é—´, $O(n^2)$ æœ€åæƒ…å†µ; å¯¹äºå¤§çš„
ã€ä¹±åºä¸²åˆ—ä¸€èˆ¬è®¤ä¸ºæ˜¯æœ€å¿«çš„å·²çŸ¥æ’åº
  * å †æ’åº ï¼ˆheapsortï¼‰: $O(nlogn)$
  * å¸Œå°”æ’åº ï¼ˆshell sortï¼‰: $O(nlogn)$
  * åŸºæ•°æ’åºï¼ˆradix sortï¼‰: $O(nÂ·k)$; éœ€è¦ $O(n)$ é¢å¤–å­˜å‚¨ç©ºé—´ ï¼ˆKä¸ºç‰¹å¾ä¸ª
æ•°ï¼‰

* ç¨³å®š
  * æ’å…¥æ’åºï¼ˆinsertion sortï¼‰: $O(n^2)$
  * å†’æ³¡æ’åºï¼ˆbubble sortï¼‰: $O(n^2)$
  * å½’å¹¶æ’åº ï¼ˆmerge sortï¼‰: $O(nlogn)$; éœ€è¦ $O(n)$ é¢å¤–å­˜å‚¨ç©ºé—´
  * äºŒå‰æ ‘æ’åºï¼ˆBinary tree sortï¼‰: $O(nlogn)$; éœ€è¦ $O(n)$ é¢å¤–å­˜å‚¨ç©ºé—´
  * è®¡æ•°æ’åº (counting sort) : $O(n+k)$; éœ€è¦ $O(n+k)$ é¢å¤–å­˜å‚¨ç©ºé—´ï¼Œkä¸ºåºåˆ—ä¸­Max-Min+1
  * æ¡¶æ’åº ï¼ˆbucket sortï¼‰: $O(n)$; éœ€è¦ $O(k)$ é¢å¤–å­˜å‚¨ç©ºé—´

### External Sort-Merge (å¤–éƒ¨æ’åºå½’å¹¶)

* relations that don't fit in memory
* Let M denote memory buffer size (in blocks)
* Create sorted runs (å½’å¹¶æ®µ)
  let ğ’Š = ğŸ initially
  repeatedly do the following till the end of the relation:
  * read M blocks of relation into memory
    sort the in-memory blocks
    write sorted data to run ğ‘¹ğ’Š
    increment ğ’Š

  let the final value of ğ’Š = ğ‘µ (N-way merge)
* Merge the runs (next slide)

## Join Operation

* examples using following information
  * #records
    * customer:10000
    * depositor:5000
  * #blocks
    * customer:400
    * depositor:100

### Nested-Loop Join (åµŒå¥—å¾ªç¯è¿æ¥)

* compute the theta join $r\bowtie_\theta S$

  ```c
  for each tuple ğ‘¡ğ‘Ÿ in ğ‘Ÿ do begin
    for each tuple ğ‘¡ğ‘  in ğ‘  do begin
      test pair (ğ‘¡ğ‘Ÿ, ğ‘¡ğ‘ ) to see if they satisfy the join condition ğœƒ
        if they do, add ğ‘¡ğ‘Ÿ âˆ™ ğ‘¡ğ‘  to the result.
    end
  end
  ```

* ğ’“ is called the outer relation (å¤–å±‚å…³ç³») and ğ’” is called the inner relation (å†…å±‚å…³ç³»)
* Require no indices and can be used for any kind of join condition
* Expensive since it examines every pair of tuples in the two relations
* In the worst case, if there is enough memory only to hold one block of each relation, the estimated cost is $n_r*b_s+b_r$ block transfers, plus $n_r + b_r$ seeks (ğ’“:outer relation (å¤–å±‚å…³ç³») ğ’”: inner relation (å†…å±‚å…³ç³») )
* If two or the smaller relation(s) fit(s) entirely in memory, use that as the inner relation.
  * Reduces cost to br + bs block transfers and 2 seeks
* **Block nested-loops algorithm** is preferable
* è¾ƒå°çš„å…³ç³»åšå†…å±‚æ›´ä¼˜

### Block Nested-Loop Join (å—åµŒå¥—å¾ªç¯è¿æ¥)

* Variant of nested-loop join in which every block of inner relation is paired with every block of outer relation.

```c
for each block ğµğ‘Ÿ of ğ‘Ÿ do begin
  for each block ğµğ‘  of ğ‘  do begin
    for each tuple ğ‘¡ğ‘Ÿ in ğµğ‘Ÿ do begin
      for each tuple ğ‘¡ğ‘  in ğµğ‘  do begin
        check if (ğ‘¡ğ‘Ÿ, ğ‘¡ğ‘ ) satisfy the join condition 
        if they do, add ğ‘¡ğ‘Ÿ âˆ™ ğ‘¡ğ‘  to the result.
      end
    end
  end
end
```
